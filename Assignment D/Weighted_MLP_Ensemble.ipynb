{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0fKkab1Tz15"
      },
      "source": [
        "# **Weighted Average MLP Ensemble**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "otlJpClTO9hn"
      },
      "source": [
        "# global optimization to find coefficients for weighted ensemble on blobs problem\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.metrics import accuracy_score\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from matplotlib import pyplot\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from numpy import array\n",
        "from numpy import argmax\n",
        "from numpy import tensordot\n",
        "from numpy.linalg import norm\n",
        "from scipy.optimize import differential_evolution"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rm-SkuoZQJ0Q"
      },
      "source": [
        "# fit model on dataset\n",
        "def fit_model(trainX, trainy):\n",
        "\ttrainy_enc = to_categorical(trainy)\n",
        "\t# define model\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Dense(25, input_dim=2, activation='relu'))\n",
        "\tmodel.add(Dense(3, activation='softmax'))\n",
        "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\t# fit model\n",
        "\tmodel.fit(trainX, trainy_enc, epochs=500, verbose=0)\n",
        "\treturn model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jq_rMnz6QPZ-"
      },
      "source": [
        "# make an ensemble prediction for multi-class classification\n",
        "def ensemble_predictions(members, weights, testX):\n",
        "\t# make predictions\n",
        "\tyhats = [model.predict(testX) for model in members]\n",
        "\tyhats = array(yhats)\n",
        "\t# weighted sum across ensemble members\n",
        "\tsummed = tensordot(yhats, weights, axes=((0),(0)))\n",
        "\t# argmax across classes\n",
        "\tresult = argmax(summed, axis=1)\n",
        "\treturn result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vJKXoIVQSyB"
      },
      "source": [
        "# evaluate a specific number of members in an ensemble\n",
        "def evaluate_ensemble(members, weights, testX, testy):\n",
        "\t# make prediction\n",
        "\tyhat = ensemble_predictions(members, weights, testX)\n",
        "\t# calculate accuracy\n",
        "\treturn accuracy_score(testy, yhat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0Ltr0k9QV4Y"
      },
      "source": [
        "# normalize a vector to have unit norm\n",
        "def normalize(weights):\n",
        "\t# calculate l1 vector norm\n",
        "\tresult = norm(weights, 1)\n",
        "\t# check for a vector of all zeros\n",
        "\tif result == 0.0:\n",
        "\t\treturn weights\n",
        "\t# return normalized vector (unit norm)\n",
        "\treturn weights / result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilCXqfeWQYXd"
      },
      "source": [
        "# loss function for optimization process, designed to be minimized\n",
        "def loss_function(weights, members, testX, testy):\n",
        "\t# normalize weights\n",
        "\tnormalized = normalize(weights)\n",
        "\t# calculate error rate\n",
        "\treturn 1.0 - evaluate_ensemble(members, normalized, testX, testy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NVDZZckYQbTi",
        "outputId": "232f2f37-e5fe-41ac-d0a6-c9ed34f1313d"
      },
      "source": [
        "# generate 2d classification dataset\n",
        "X, y = make_blobs(n_samples=1100, centers=3, n_features=2, cluster_std=2, random_state=2)\n",
        "# split into train and test\n",
        "n_train = 100\n",
        "trainX, testX = X[:n_train, :], X[n_train:, :]\n",
        "trainy, testy = y[:n_train], y[n_train:]\n",
        "print(trainX.shape, testX.shape)\n",
        "# fit all models\n",
        "n_members = 3\n",
        "members = [fit_model(trainX, trainy) for _ in range(n_members)]\n",
        "# evaluate each single model on the test set\n",
        "testy_enc = to_categorical(testy)\n",
        "for i in range(n_members):\n",
        "\t_, test_acc = members[i].evaluate(testX, testy_enc, verbose=0)\n",
        "\tprint('Model %d: %.3f' % (i+1, test_acc))\n",
        "# evaluate averaging ensemble (equal weights)\n",
        "weights = [1.0/n_members for _ in range(n_members)]\n",
        "score = evaluate_ensemble(members, weights, testX, testy)\n",
        "print('Equal Weights Score: %.3f' % score)\n",
        "# define bounds on each weight\n",
        "bound_w = [(0.0, 1.0)  for _ in range(n_members)]\n",
        "# arguments to the loss function\n",
        "search_arg = (members, testX, testy)\n",
        "# global optimization of ensemble weights\n",
        "result = differential_evolution(loss_function, bound_w, search_arg, maxiter=1000, tol=1e-7)\n",
        "# get the chosen weights\n",
        "weights = normalize(result['x'])\n",
        "print('Optimized Weights: %s' % weights)\n",
        "# evaluate chosen weights\n",
        "score = evaluate_ensemble(members, weights, testX, testy)\n",
        "print('Optimized Weights Score: %.3f' % score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(100, 2) (1000, 2)\n",
            "Model 1: 0.808\n",
            "Model 2: 0.810\n",
            "Model 3: 0.811\n",
            "Equal Weights Score: 0.811\n",
            "Optimized Weights: [0.0652782  0.35024905 0.58447275]\n",
            "Optimized Weights Score: 0.816\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}