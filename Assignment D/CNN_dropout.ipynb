{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5j_qD6437PBG"
      },
      "source": [
        "# **CNN Dropout**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8TJR8oxFQxD",
        "outputId": "d69d1650-42fb-4b24-b13b-e2f1ed1b0b13"
      },
      "source": [
        "# TensorFlow and tf.keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
        "\n",
        "# Commonly used modules\n",
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# Images, plots, display, and visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import cv2\n",
        "import IPython\n",
        "from six.moves import urllib\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3r9HVegJFlYT",
        "outputId": "7c1f0f33-50e1-4c0b-c8dc-9a82ada24b38"
      },
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = keras.datasets.mnist.load_data()\n",
        "# reshape images to specify that it's a single channel\n",
        "print(test_labels.shape)\n",
        "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1)\n",
        "test_images = test_images.reshape(test_images.shape[0], 28, 28, 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "(10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vw6eSgnPIVQX"
      },
      "source": [
        "def preprocess_images(imgs): # should work for both a single image and multiple images\n",
        "    sample_img = imgs if len(imgs.shape) == 2 else imgs[0]\n",
        "    assert sample_img.shape in [(28, 28, 1), (28, 28)], sample_img.shape # make sure images are 28x28 and single-channel (grayscale)\n",
        "    return imgs / 255.0\n",
        "\n",
        "train_images = preprocess_images(train_images)\n",
        "test_images = preprocess_images(test_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "NzCAHB2IIg-5",
        "outputId": "8af7c3a4-c3c2-472a-c5a4-f43b03746d34"
      },
      "source": [
        "plt.figure(figsize=(10,2))\n",
        "for i in range(10,15):\n",
        "    plt.subplot(1,5,i-9)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(train_images[i].reshape(28, 28), cmap=plt.cm.binary)\n",
        "    plt.xlabel(train_labels[i])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x144 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSKCHe3s3XRb"
      },
      "source": [
        "2. Annotate the sizes of the mathematical objects within; inputs, outputs, filters, etc.  \n",
        "\n",
        "The input to the neural network are 28 X 28 images- the train set has 60000 images and test set has 10000 images.\n",
        "\n",
        "The output vector is a 10 element one hot vector that maps the output to numbers ranging from 0-9\n",
        "\n",
        "The model-\n",
        "\n",
        "> 1 layer- 32 convolution filters of size 3 x 3\n",
        "\n",
        ">2 layer- 64 convolution filters of size 3 x 3 x 32\n",
        "\n",
        ">3 layer- max-pool filter of size 2 x 2\n",
        "\n",
        ">4 layer- fully conected layer with 128 neurons connnected with max pool layer\n",
        "\n",
        ">Output layer- 10 neurons fully connected with layer 4\n",
        "\n",
        "\n",
        "The ouputs of each layer and the weights of fully connected layers-\n",
        "\n",
        ">1 layer-26 x 26 x 32\n",
        "\n",
        ">2 layer- 24 x 24 x 64\n",
        "\n",
        ">3 layer- 23 x 23 x 64\n",
        "\n",
        ">4 layer- 128 outputs from 33,856 inputs- which gives us 4,333,568 weights and 128 biases\n",
        "\n",
        ">Output layer- 10 outputs from 128 inputs- which gives us 1,280 weights and 10 biases\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VXaWSk7Nvgl"
      },
      "source": [
        "model = keras.Sequential()\n",
        "# 32 convolution filters used each of size 3x3\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "# 64 convolution filters used each of size 3x3\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "# choose the best features via pooling\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "# randomly turn neurons on and off to improve convergence\n",
        "model.add(Dropout(0.25))\n",
        "# flatten since too many dimensions, we only want a classification output\n",
        "model.add(Flatten())\n",
        "# fully connected to get all relevant data\n",
        "model.add(Dense(128, activation='relu'))\n",
        "# one more dropout\n",
        "model.add(Dropout(0.5))\n",
        "# output a softmax to squash the matrix into output probabilities\n",
        "model.add(Dense(10, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcG5jGYC62kN"
      },
      "source": [
        "3. How is dropout applied?\n",
        "\n",
        "Dropout is applied to the previous layer where the arrgument represents the chance with which a neurons activation will be 0.\n",
        "\n",
        "eg- 0.5 means that there is a 50% chance of dropout for each neuron in the layer before "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UqPd67iFUF-H"
      },
      "source": [
        "model.compile(optimizer=tf.optimizers.Adam(), \n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jnm3HfnwU1QI",
        "outputId": "995b2b24-6ea3-4459-eb5a-a59b3d8b84dc"
      },
      "source": [
        "history = model.fit(train_images, train_labels, epochs=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 145s 77ms/step - loss: 0.3605 - accuracy: 0.8879\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 146s 78ms/step - loss: 0.0787 - accuracy: 0.9760\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 147s 78ms/step - loss: 0.0587 - accuracy: 0.9820\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 148s 79ms/step - loss: 0.0477 - accuracy: 0.9855\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 150s 80ms/step - loss: 0.0415 - accuracy: 0.9864\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59rvw8-RgzYE",
        "outputId": "e1ddf824-7f65-45e0-fef4-082594fa591a"
      },
      "source": [
        "print(test_images.shape)\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "\n",
        "print('Test accuracy:', test_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 28, 28, 1)\n",
            "313/313 [==============================] - 6s 20ms/step - loss: 0.0308 - accuracy: 0.9903\n",
            "Test accuracy: 0.9902999997138977\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SqMEt1fX7cRF"
      },
      "source": [
        "4. What is the performance with Dropout enabled?\n",
        "\n",
        "There is very high accurancy for both the training set and the test set while using drop out. The varience between both the training accuracy and the test accuracy is also quite low"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQzMcEALUp6E"
      },
      "source": [
        "# Removing Dropout"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgrNXEv25dZm"
      },
      "source": [
        "model2 = keras.Sequential()\n",
        "# 32 convolution filters used each of size 3x3\n",
        "model2.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "# 64 convolution filters used each of size 3x3\n",
        "model2.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "# choose the best features via pooling\n",
        "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "# flatten since too many dimensions, we only want a classification output\n",
        "model2.add(Flatten())\n",
        "# fully connected to get all relevant data\n",
        "model2.add(Dense(128, activation='relu'))\n",
        "# output a softmax to squash the matrix into output probabilities\n",
        "model2.add(Dense(10, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lriyh8315rLG"
      },
      "source": [
        "model2.compile(optimizer=tf.optimizers.Adam(), \n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-iiuq6i_5ufP",
        "outputId": "eb6b06b6-e5c3-4036-f948-49f109b8212c"
      },
      "source": [
        "history = model2.fit(train_images, train_labels, epochs=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 145s 77ms/step - loss: 0.2481 - accuracy: 0.9223\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 144s 77ms/step - loss: 0.0365 - accuracy: 0.9887\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 145s 77ms/step - loss: 0.0215 - accuracy: 0.9927\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 144s 77ms/step - loss: 0.0130 - accuracy: 0.9958\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 145s 77ms/step - loss: 0.0111 - accuracy: 0.9962\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SdILwpVW9Tnj",
        "outputId": "4374ef99-d390-4630-9930-9416b39ca6e0"
      },
      "source": [
        "print(test_images.shape)\n",
        "test_loss, test_acc = model2.evaluate(test_images, test_labels)\n",
        "\n",
        "print('Test accuracy:', test_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 28, 28, 1)\n",
            "313/313 [==============================] - 6s 20ms/step - loss: 0.0421 - accuracy: 0.9894\n",
            "Test accuracy: 0.9894000291824341\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYrk7FIh7ytz"
      },
      "source": [
        "5. Now disable it. What is the performance?\n",
        "\n",
        "Disabling dropout we can notice the accuracy of the training set increased but there is a slighty larger gap in accuracy between the training set and the test set. This may imply a case of slight overfitting to the Training set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cp29SDCU2Vm"
      },
      "source": [
        "# Increasing the probability of Dropout"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eh_hriRbCWf8"
      },
      "source": [
        "model3 = keras.Sequential()\n",
        "# 32 convolution filters used each of size 3x3\n",
        "model3.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "# 64 convolution filters used each of size 3x3\n",
        "model3.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "# choose the best features via pooling\n",
        "model3.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "# randomly turn neurons on and off to improve convergence\n",
        "model3.add(Dropout(0.5))\n",
        "# flatten since too many dimensions, we only want a classification output\n",
        "model3.add(Flatten())\n",
        "# fully connected to get all relevant data\n",
        "model3.add(Dense(128, activation='relu'))\n",
        "# one more dropout\n",
        "model3.add(Dropout(0.7))\n",
        "# output a softmax to squash the matrix into output probabilities\n",
        "model3.add(Dense(10, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tUlOk8KGCy9Q"
      },
      "source": [
        "model3.compile(optimizer=tf.optimizers.Adam(), \n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iy2wjasiC3Vx",
        "outputId": "3d08a365-a0b8-4732-c210-0b7d79530e94"
      },
      "source": [
        "history = model3.fit(train_images, train_labels, epochs=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 151s 80ms/step - loss: 0.5483 - accuracy: 0.8233\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 150s 80ms/step - loss: 0.1664 - accuracy: 0.9509\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 150s 80ms/step - loss: 0.1287 - accuracy: 0.9623\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 149s 80ms/step - loss: 0.1028 - accuracy: 0.9681\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 150s 80ms/step - loss: 0.0955 - accuracy: 0.9712\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8TGwbUeC7my",
        "outputId": "d34178c6-478d-40ca-a6b7-109e587c5bfd"
      },
      "source": [
        "print(test_images.shape)\n",
        "test_loss, test_acc = model3.evaluate(test_images, test_labels)\n",
        "\n",
        "print('Test accuracy:', test_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 28, 28, 1)\n",
            "313/313 [==============================] - 6s 20ms/step - loss: 0.0294 - accuracy: 0.9899\n",
            "Test accuracy: 0.9898999929428101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1bUdy6UVAMw"
      },
      "source": [
        "# Using a lower probability of Dropout"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_lKdBrRC-YU"
      },
      "source": [
        "model4 = keras.Sequential()\n",
        "# 32 convolution filters used each of size 3x3\n",
        "model4.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "# 64 convolution filters used each of size 3x3\n",
        "model4.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "# choose the best features via pooling\n",
        "model4.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "# randomly turn neurons on and off to improve convergence\n",
        "model4.add(Dropout(0.1))\n",
        "# flatten since too many dimensions, we only want a classification output\n",
        "model4.add(Flatten())\n",
        "# fully connected to get all relevant data\n",
        "model4.add(Dense(128, activation='relu'))\n",
        "# one more dropout\n",
        "model4.add(Dropout(0.1))\n",
        "# output a softmax to squash the matrix into output probabilities\n",
        "model4.add(Dense(10, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmIpJgKYDc_z"
      },
      "source": [
        "model4.compile(optimizer=tf.optimizers.Adam(), \n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YqotOthMDfmH",
        "outputId": "b25e28d0-117f-4de2-aa0d-1601c2d946ed"
      },
      "source": [
        "history = model4.fit(train_images, train_labels, epochs=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 152s 81ms/step - loss: 0.0123 - accuracy: 0.9959\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 151s 81ms/step - loss: 0.0087 - accuracy: 0.9972\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 152s 81ms/step - loss: 0.0088 - accuracy: 0.9972\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 152s 81ms/step - loss: 0.0072 - accuracy: 0.9976\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 153s 81ms/step - loss: 0.0077 - accuracy: 0.9973\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SX06yiUYDjIe",
        "outputId": "ee1a70e6-4bbe-4751-b610-fd82a9d98eeb"
      },
      "source": [
        "print(test_images.shape)\n",
        "test_loss, test_acc = model4.evaluate(test_images, test_labels)\n",
        "\n",
        "print('Test accuracy:', test_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 28, 28, 1)\n",
            "313/313 [==============================] - 6s 20ms/step - loss: 0.0452 - accuracy: 0.9917\n",
            "Test accuracy: 0.9916999936103821\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwwOgXx89nf8"
      },
      "source": [
        "6 and 7\n",
        "\n",
        "Altering the dropout in model 3 we can see that increasing drop out to a higher extent- Lowers the DOF of the model drastically while training as most of the neurons get turned off and the much of the useful data is lost. This leads to a lower accuracy in both the training and test set. We can also see a larger gap between the accuracy of the test and training set.\n",
        "\n",
        "Altering the dropout in model 4 we can see that decreasing the dropout closer to 0 brings us closer to a model that doesnt have drop out but also gives us the benfits of generalization of dropout. The accuracy of the training set is close to the model with no dropout. The gap in the accuracy of the test set and the train set is also quite low; it is comparable to the first model.\n",
        "\n",
        "We can see that there is no definate value of dropot that will give us the best model for our problem. This is why this is a hyperparameter of the model and has to be empirically choosen by us.\n",
        "\n"
      ]
    }
  ]
}